{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "from pyquery import PyQuery as pq\n",
    "import time \n",
    "import random\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global config\n",
    "headers = {\n",
    "    'Host': 'm.weibo.cn',\n",
    "    'Referer': 'https://m.weibo.cn/search?containerid=100103type%3D1%26q%3D%E8%B4%B8%E6%98%93%E6%88%98',\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0.2 Safari/605.1.15',\n",
    "    'X-Requested-With': 'XMLHttpRequest',\n",
    "    'MWeibo-Pwa': '1'\n",
    "}\n",
    "save_dir = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request function, with retry\n",
    "def fetch(url, headers=headers):\n",
    "    retry_time = 0\n",
    "    \n",
    "    while retry_time < 5:\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            return response.json()\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Retry:', url)\n",
    "            retry_time += 1\n",
    "            time.sleep(random.randint(2, 4))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save JSON in data directory\n",
    "def save_json(result, title):\n",
    "    path = os.path.join(save_dir, '%s.json'%title)\n",
    "    with open(path, 'wb') as f:\n",
    "        f.write(json.dumps(result, ensure_ascii=False, indent=2).encode('utf-8'))\n",
    "        f.write('\\r\\n'.encode('utf-8'))\n",
    "    print('save file at', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy a JSON with some specific keys\n",
    "def copy_dict(ori, keys):\n",
    "    dest = {}\n",
    "    for key in keys:\n",
    "        dest[key] = ori.get(key)\n",
    "    return dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract useful keys from JSON\n",
    "def process_user(user):\n",
    "    return copy_dict(user, ['id', 'verified', 'verified_type', 'gender', 'followers_count', 'follow_count', 'verified_type_ext', 'screen_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract useful keys from JSON\n",
    "def process_comment(comment):\n",
    "    ret = copy_dict(comment, ['like_counts', 'created_at', 'text'])\n",
    "    ret['user'] = process_user(comment.get('user'))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract weibo information\n",
    "def process_item(item):\n",
    "    \n",
    "    assert item.get('card_type') == 9\n",
    "    mblog = item.get('mblog')\n",
    "    ret = copy_dict(mblog, ['id', 'created_at', 'attitudes_count'])\n",
    "    \n",
    "    text = mblog.get('text')\n",
    "    if 'longText' in mblog:\n",
    "        text = mblog.get('longText').get('longTextContent')\n",
    "    ret['text'] = text\n",
    "    \n",
    "    user_origin = mblog.get('user')\n",
    "    ret['user'] = process_user(user_origin)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judge if response is valid\n",
    "def is_res_valid(res):\n",
    "    return res is not None and res.get('ok') == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch weibo list by query word IN SINGLE PAGE\n",
    "def get_weibos(query, page=''):\n",
    "    base_url = 'https://m.weibo.cn/api/container/getIndex?'\n",
    "    params = {\n",
    "        'containerid': '100103type=1&q=%s'%query,\n",
    "        'page_type': 'searchall',\n",
    "        'page': page\n",
    "    }\n",
    "    url = base_url + urlencode(params)\n",
    "    print(url)\n",
    "    return fetch(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch comments of a weibo\n",
    "def get_comments(id, start_page=1):\n",
    "    ret = []\n",
    "    base_url = 'https://m.weibo.cn/api/comments/show?'\n",
    "    page = start_page\n",
    "    while True:\n",
    "        params = {\n",
    "        'id': id,\n",
    "        'page': page\n",
    "        }\n",
    "        url = base_url + urlencode(params)\n",
    "        \n",
    "        response_json = fetch(url)\n",
    "        if not is_res_valid(response_json):\n",
    "            break\n",
    "        \n",
    "        data = response_json.get('data').get('data')\n",
    "        for comment in data:\n",
    "            ret.append(process_comment(comment))\n",
    "            \n",
    "        page += 1\n",
    "        time.sleep(random.randint(0, 3))\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all weibos with query word, then form an output list\n",
    "def collect_weibo(query, max_page=10, start_page=1):\n",
    "    ret = []\n",
    "    start_page = max(start_page, 1)\n",
    "    \n",
    "    for page in range(start_page, max_page+1):\n",
    "        response_json = get_weibos(query, page)\n",
    "        comments_in_page = 0\n",
    "        \n",
    "        if is_res_valid(response_json):\n",
    "            cards = response_json.get('data').get('cards', {})\n",
    "            \n",
    "            for card in cards:\n",
    "                \n",
    "                if 'card_group' not in card: continue\n",
    "                for item in card['card_group']:\n",
    "                    if item.get('card_type') != 9: continue\n",
    "                        \n",
    "                    weibo = process_item(item)\n",
    "                    comments = get_comments(weibo.get('id'))\n",
    "                    \n",
    "                    weibo['comments'] = comments\n",
    "                    comments_in_page += len(comments)\n",
    "                    \n",
    "                    ret.append(weibo)\n",
    "            print('Fetch totally %d records. (%d new comments)'%(len(ret), comments_in_page))\n",
    "            time.sleep(random.randint(1, 3))\n",
    "        else:\n",
    "            print('Result invalid:')\n",
    "            print('Query: %s, page: %d'%(query, page))\n",
    "            break\n",
    "            \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each query, output an JSON object\n",
    "def run(querys, save=True):\n",
    "    if isinstance(querys, str):\n",
    "        querys = [querys]\n",
    "    \n",
    "    for query in querys:\n",
    "        print('---------------------------------------')\n",
    "        print('Fetching \"%s\"'%query)\n",
    "        result = collect_weibo(query, 100, start_page=1)\n",
    "        output = {\n",
    "            'query': query,\n",
    "            'result': result\n",
    "        }\n",
    "\n",
    "        if save:\n",
    "            save_json(output, '%s'%(query.replace(' ', '_')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "#     'G20 重启经贸磋商',\n",
    "#     '推迟 贸易代表莱特希泽 汽车贸易 谈判',\n",
    "#     '美国进入紧急状态 电信设备 实体名单',\n",
    "#     '国务院关税税则委员会 提高加征关税税率',\n",
    "#     '美国贸易代表办公室 3000亿',\n",
    "#     '美国对中国2000亿美元商品开始加征25%关税',\n",
    "#     '商务部发言人 深表遗憾 不得不采取必要反制措施',\n",
    "#     '美国贸易代表办公室宣布对华2000亿美元商品关税从10%提升到25%',\n",
    "#     '开始对中国2000亿美元的输美商品加征25%关税',\n",
    "#     '美国贸易代表团应邀访华 第八轮中美经贸高级别磋商',\n",
    "#     '将推迟提高对华关税税率 并可能计划第二次中美首脑峰会',\n",
    "    '中方牵头人刘鹤 新一轮中美经贸高级别磋商'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Fetching \"中方牵头人刘鹤 新一轮中美经贸高级别磋商\"\n",
      "https://m.weibo.cn/api/container/getIndex?containerid=100103type%3D1%26q%3D%E4%B8%AD%E6%96%B9%E7%89%B5%E5%A4%B4%E4%BA%BA%E5%88%98%E9%B9%A4+%E6%96%B0%E4%B8%80%E8%BD%AE%E4%B8%AD%E7%BE%8E%E7%BB%8F%E8%B4%B8%E9%AB%98%E7%BA%A7%E5%88%AB%E7%A3%8B%E5%95%86&page_type=searchall&page=1\n",
      "Fetch totally 9 records. (5 new comments)\n",
      "https://m.weibo.cn/api/container/getIndex?containerid=100103type%3D1%26q%3D%E4%B8%AD%E6%96%B9%E7%89%B5%E5%A4%B4%E4%BA%BA%E5%88%98%E9%B9%A4+%E6%96%B0%E4%B8%80%E8%BD%AE%E4%B8%AD%E7%BE%8E%E7%BB%8F%E8%B4%B8%E9%AB%98%E7%BA%A7%E5%88%AB%E7%A3%8B%E5%95%86&page_type=searchall&page=2\n",
      "Fetch totally 12 records. (20 new comments)\n",
      "https://m.weibo.cn/api/container/getIndex?containerid=100103type%3D1%26q%3D%E4%B8%AD%E6%96%B9%E7%89%B5%E5%A4%B4%E4%BA%BA%E5%88%98%E9%B9%A4+%E6%96%B0%E4%B8%80%E8%BD%AE%E4%B8%AD%E7%BE%8E%E7%BB%8F%E8%B4%B8%E9%AB%98%E7%BA%A7%E5%88%AB%E7%A3%8B%E5%95%86&page_type=searchall&page=3\n",
      "Result invalid:\n",
      "Query: 中方牵头人刘鹤 新一轮中美经贸高级别磋商, page: 3\n",
      "save file at ./data\\中方牵头人刘鹤_新一轮中美经贸高级别磋商.json\n"
     ]
    }
   ],
   "source": [
    "run(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://m.weibo.cn/api/container/getIndex?containerid=100103type%3D1%26q%3D%E5%95%86%E5%8A%A1%E9%83%A8%E5%8F%91%E8%A8%80%E4%BA%BA+%E6%B7%B1%E8%A1%A8%E9%81%97%E6%86%BE+%E4%B8%8D%E5%BE%97%E4%B8%8D%E9%87%87%E5%8F%96%E5%BF%85%E8%A6%81%E5%8F%8D%E5%88%B6%E6%8E%AA%E6%96%BD&page_type=searchall&page=1\n",
      "Fetch 9 records and 5 comments\n",
      "https://m.weibo.cn/api/container/getIndex?containerid=100103type%3D1%26q%3D%E5%95%86%E5%8A%A1%E9%83%A8%E5%8F%91%E8%A8%80%E4%BA%BA+%E6%B7%B1%E8%A1%A8%E9%81%97%E6%86%BE+%E4%B8%8D%E5%BE%97%E4%B8%8D%E9%87%87%E5%8F%96%E5%BF%85%E8%A6%81%E5%8F%8D%E5%88%B6%E6%8E%AA%E6%96%BD&page_type=searchall&page=2\n",
      "Fetch 17 records and 6 comments\n",
      "https://m.weibo.cn/api/container/getIndex?containerid=100103type%3D1%26q%3D%E5%95%86%E5%8A%A1%E9%83%A8%E5%8F%91%E8%A8%80%E4%BA%BA+%E6%B7%B1%E8%A1%A8%E9%81%97%E6%86%BE+%E4%B8%8D%E5%BE%97%E4%B8%8D%E9%87%87%E5%8F%96%E5%BF%85%E8%A6%81%E5%8F%8D%E5%88%B6%E6%8E%AA%E6%96%BD&page_type=searchall&page=3\n",
      "Result invalid:\n",
      "Query: 商务部发言人 深表遗憾 不得不采取必要反制措施, page: 3\n",
      "save file at ./data\\商务部发言人_深表遗憾_不得不采取必要反制措施.json\n"
     ]
    }
   ],
   "source": [
    "# 测试 run 函数\n",
    "query = '商务部发言人 深表遗憾 不得不采取必要反制措施'\n",
    "run(query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
